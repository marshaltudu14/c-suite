// app/api/chat/route.js
import { createOllama } from "ollama-ai-provider";
import { streamText } from "ai";
import { createClient } from "@/utils/supabase/server";

const ollama = createOllama();

export async function POST(req) {
  try {
    const { messages, systemPrompt, companyDetails, selectedPerson } =
      await req.json();

    // Initialize Supabase client
    const supabase = await createClient();
    
    // Get the current user
    const { data: { user } } = await supabase.auth.getUser();
    const userId = user?.id;

    // Get the last user message to save to Supabase
    const lastUserMessage = messages.length > 0 ? messages[messages.length - 1] : null;

    // Save user message to Supabase if it exists
    if (lastUserMessage && lastUserMessage.role === "user" && userId) {
      // Save the user message to chat_history
      await supabase.from("chat_history").insert({
        user_id: userId,
        message: lastUserMessage.content,
        role: "user",
        agent: selectedPerson?.id || "default"
      });
    }

    // Combine systemPrompt with userDetails for context
    let fullSystemPrompt = systemPrompt || "";
    if (companyDetails) {
      const companyDetailsString = JSON.stringify(companyDetails, null, 2); // Pretty-print JSON

      fullSystemPrompt += `\n\n---\n\n### User Company Information\nThe following section contains details about the user's company, which is the company you work for as an AI assistant. This is **not about you**â€”it's external context about the user's organization. Use this information to personalize your responses as if you are a colleague within this company, aligning your answers with its mission, vision, policies, and other details.\n\n${companyDetailsString}\n\n### Instructions\n- The text before the 'User Company Information' section defines **your role, personality, and expertise** as an AI ${selectedPerson.position}. Treat this as your identity and behavior guidelines.\n- The 'User Company Information' section is **the user's company context**. Use it to tailor your responses to their specific company, but do not confuse it with your own identity or role.\n- Respond factually based on the company details provided. Never provide a general solution. If you don't have enough information, ask the user to provide more information by specific what information you need exactly to assist the user.\n- Maintain a professional, colleague-like tone, acting as if you work within the user's company."`;
    }

    // Call Ollama with your chosen model
    const result = await streamText({
      model: ollama("llama3.2b"),
      system: fullSystemPrompt,
      messages: messages,
      onCompletion: async (completion) => {
        // Save the complete assistant response to Supabase
        if (userId) {
          await supabase.from("chat_history").insert({
            user_id: userId,
            message: completion,
            role: "assistant",
            agent: selectedPerson?.id || "default"
          });
        }
      },
    });

    // Create a TransformStream to intercept the streamed response
    // This allows us to save chunks of the response in real-time
    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    
    // Get the original readable stream from the result
    const originalStream = result.toDataStreamResponse().body;
    
    if (originalStream && userId) {
      // Create a reader for the original stream
      const reader = originalStream.getReader();
      
      // Buffer to accumulate the assistant's response
      let responseBuffer = '';
      const messageId = `${userId}-${Date.now()}-${selectedPerson?.id || "default"}`;
      
      // Process the stream
      (async () => {
        try {
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              writer.close();
              break;
            }
            
            // Pass through the chunk to the client
            writer.write(value);
            
            // Decode and accumulate the response
            const chunk = new TextDecoder().decode(value);
            
            // Extract the actual text content from the chunk
            // The format is typically: data: {"type":"text","value":"..."}
            try {
              const match = chunk.match(/data: (.+)(?:\n|$)/);
              if (match) {
                const data = JSON.parse(match[1]);
                if (data.type === 'text') {
                  responseBuffer += data.value;
                  
                  // Save partial response to Supabase if we have a user ID
                  // Only save when we have a complete sentence or every 100 chars
                  if (responseBuffer.match(/[.!?](\s|$)/) || responseBuffer.length > 100) {
                    await supabase.from("chat_history").upsert({
                      id: messageId,
                      user_id: userId,
                      message: responseBuffer,
                      role: "assistant",
                      agent: selectedPerson?.id || "default"
                    }, { onConflict: 'id' });
                  }
                }
              }
            } catch (e) {
              // Ignore parsing errors and continue
              console.error("Error parsing chunk:", e);
            }
          }
        } catch (error) {
          console.error("Error processing stream:", error);
          writer.abort(error);
        }
      })();
      
      // Return the transformed stream as the response
      return new Response(readable, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    }
    
    // If no user ID or no original stream, return the original response
    return result.toDataStreamResponse();
  } catch (error) {
    console.error("Error in /api/chat:", error);
    return new Response("Failed to call Ollama model.", { status: 500 });
  }
}